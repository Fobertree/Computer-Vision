What makes this different from edges?
\begin{itemize}
    \item Edge only give parts where pixels change rapidly, but lines give us structure
\end{itemize}
Fitting as Search in Parametric Space
\begin{itemize}
    \item Parametric model for a set of features
    \item Computational complexity matters
\end{itemize}
Difficulty of line fitting
\begin{itemize}
    \item Edge point clutter
    \item Only some parts of line detected, some fitting
    \item Noise in measured edge points
    \begin{itemize}
        \item How to detect true underlying parameters?
    \end{itemize}
\end{itemize}
\subsection{RANSAC}
Overview
\begin{itemize}
    \item RANdom SAmple Consensus
    \item Approach: Avoid impact of outliers
    \item Iteratively maximize number of inlines
    \begin{itemize}
        \item Least-squares
    \end{itemize}
\end{itemize}
Task: Estimate the best line\\
RANSAC stage (k iterations)
\begin{itemize}
    \item Randomly pick 2 points, create a line from the two points
    \item Find total number of points within a (distance) threshold of line (inlier points)
    \item Repeat, until we get a good result
\end{itemize}
Refinement stage (repeat until the inliner set is stable)
\begin{itemize}
    \item Take all inliners of the best line
    \item Fit a new line using least squares (linear regression)
    \item Re-check which points are inliners
    \item Keep doing this until inliner set is stable (number of inliner points doesn't change, i.e. size of set remains the same)
\end{itemize}
Pros
\begin{itemize}
    \item General method suited for a wide range of model fitting problesm
    \item Easy to implement
\end{itemize}
Cons
\begin{itemize}
    \item Only handles a moderate number of outliers before cost blowing up
    \item Many problems have high rates of outliers
\end{itemize}

\subsection{Hough Transform}
Hough transform can detect lines, circles, and structures ONLY if their parametric equations are known\vspace{0.15in}\\
Naive line detection
\begin{itemize}
    \item For every pair of edge pixels
    \begin{itemize}
        \item Compute equation of line
        \item Check if other pixels satisfy equation
        \item $O(N^2)$ for $N$ edge pixels. Too expensive
    \end{itemize}
\end{itemize}
Idea
\begin{itemize}
    \item Take one edge point $(x_i,y_i)$
    \begin{itemize}
        \item Many potential lines passing through point
        \item Family of lines has form $y_i = a*x_i +b$
    \end{itemize}
    \item Original $(x,y)$ space is in image space
    \[y=a_i*x+b_i\]
    \item $a,b$ values get mapped to ``parameter space" $(a,b)$
    \begin{itemize}
        \item Since $a,b$ are inversely proportional, $(a_1,b_1)$ and $(a_2,b_2)$ produce negative sloping line: $b=-x_i * a + y_i$
        \[b=-x_i*a+y_i\]
        \begin{itemize}
            \item \textbf{Proof for this:} subtract $a_i * x$ from both sides
        \end{itemize}
        \item All the feasible combinations of $(a,b)$ are on the same line in the parameter space
        \item Note that since $x_i$ and $y_i$ are our new fixed constants (our $m$ and $b$ in $y=mx+b$) each point $(x_i,y_i)$ produces a new line in parameter space
    \end{itemize}
\end{itemize}
Detecting lines using Hough transform
\begin{itemize}
    \item Each point produces a new line in the parameter space
    \item The intersection of the lines in the parameter space provide $(a^\prime,b^\prime)$, which forms the line $y=a^\prime*x + b^\prime$, which represents the equation in the original image space that connects the two points
    \begin{itemize}
        \item Proof also by algebra, in moving $ax$ term
    \end{itemize}
    \item Convert parameter space into discretized cells in a grid
    \begin{itemize}
        \item We vote on the discrete cells that are `activated' by the transformed line in $(a^\prime, b^\prime)$. Increment cells it is passing through by $1$
        \item Find cells with more votes than threshold
        \begin{itemize}
            \item Intuitively, finding lines that correspond to the most edge points
        \end{itemize}
    \end{itemize}
    \item Complexity
    \begin{itemize}
        \item Linear on number of edge points $N$
        \item Linear on number of accumulator cells $M$
        \item $O(N\times M)$
    \end{itemize}
\end{itemize}

\subsection{Local Invariant Features}
It can be difficult to find matching images, depending on angle, color hue, shadows, etc.
\begin{itemize}
    \item However, if we can find local features to identify a local appearance, we can match regions across different images
    \item Ex: NASA Mars Rover with SIFT feature matching
\end{itemize}
Motivation for using local features
\begin{itemize}
    \item Global representations have major limitations
    \item Increased robustness to occulusions
    \begin{itemize}
        \item Occlusions
        \begin{itemize}
            \item Book covering half of face
        \end{itemize}
        \item Articulation
        \item Intra-category variations
        \begin{itemize}
            \item Ex: Koalas have different noses
        \end{itemize}
    \end{itemize}
\end{itemize}
General Approach
\begin{itemize}
    \item Find a set of distinctive key-points
    \item Define a region around each keypoint
    \item Extract and normalize the region content
    \item Compute a local descriptor from normalized regions
    \item Match local descriptors
\end{itemize}
Common Requirements
\begin{itemize}
    \item Detect the same point independently in both images
    \begin{itemize}
        \item Particularly when taking images from different angles of the same subject
        \item We need reliable and distinctive descriptors
        \item Feature invariances: geometric transformations
        \item Feature invariances: photometric transformations (i.e. lighting/color)
    \end{itemize}
\end{itemize}
Introducing the Harris Corner Detector

\subsection{Harris Corner Detector}
Keypoint goals
\begin{itemize}
    \item Repeatable detection
    \item Precise localization
    \item Interesting content
\end{itemize}
Key properties of corners:
\begin{itemize}
    \item Image gradient has two or more prominent dominant directions
    \begin{itemize}
        \item Whereas, an edge only has intensity change in one direction
    \end{itemize}
    \item Repeatable and distinctive
\end{itemize}
Harris Detector Formulation
\begin{itemize}
    \item Localize patches that result in a large change of intensity when shifted in any direction
    \item When shift by $[u,v]$, the intensity change at the center pixel is
    \[I(x+u,y+v)\]
    \item When we shift by $[u,v]$, the change in intensity for the ``small window" is the energy function:
    \[E(u,v)=\sum_{x,y} w(x,y) [I(x+u,y+v)-I(x,y)]^2\]
    \begin{itemize}
        \item Window function: $w(x,y)$. This is either Heaviside step (1 in window, 0 outside) or Gaussian distribution. Basically multiplies everything by weights
    \end{itemize}
\end{itemize}
\[E(u,v)\approx \begin{bmatrix}
    u&v
\end{bmatrix}M\begin{bmatrix}
    u\\v
\end{bmatrix}\]
where $M$ (second-moment autocorrelation matrix) is:
\[M=\sum_{x,y}w(x,y)\begin{bmatrix}
    I_x^2&I_xI_y\\I_xI_y&I_y^2
\end{bmatrix}\]
Since $M=\sum_{x,y}w(x,y)\begin{bmatrix}
    I_x^2&I_xI_y\\I_xI_y&I_y^2
\end{bmatrix}$ is symmetric, we can rewrite $M=R^{-1}\begin{bmatrix}
    \lambda_1 &0\\0&\lambda_2
\end{bmatrix}R$
Note on eigenpairs
\begin{itemize}
    \item The matrix diagonalization helps denote the two dominant directions with strongest change
\end{itemize}
Cases of interpreting eigenvalues
\begin{itemize}
    \item If one is large and other is small: edge
    \item If both are large: corner
    \item If both are small: ``flat" region (none)
\end{itemize}
This computation is done thorough the Corner Response Function
\[\theta=det(M)-\alpha trace(M)^2=\lambda_1\lambda_2-\alpha(\lambda_1+\lambda_2)^2\]
\begin{itemize}
    \item The fast approximation avoids computing the eigenvalues, which requires the expensive matrix diagonalization
    \item Note: $\alpha$ is a constant (0.04 to 0.06)
    \item $\theta<0$: Edge
    \item $\theta>0$: Corner
    \item $\theta\approx 0$: ``Flat" region
\end{itemize}
Window Function
\begin{itemize}
    \item Option 1: uniform window
    \[M=\sum_{x,y}w(x,y)\begin{bmatrix}
    I_x^2&I_xI_y\\I_xI_y&I_y^2
\end{bmatrix}\]
    \begin{itemize}
        \item Flaw, sensitive to rotation
    \end{itemize}
    \item Option 2: gaussian smoothing
    \[M= g(\sigma)*\sum_{x,y}w(x,y)\begin{bmatrix}
    I_x^2&I_xI_y\\I_xI_y&I_y^2
\end{bmatrix}\]
    \begin{itemize}
        \item Better, used by Harris detector
    \end{itemize}
\end{itemize}
Harris Detector
\begin{itemize}
    \item Compute second moment matrix (autocorrelation matrix)
    \[M(\sigma_1, \sigma_D)= g(\sigma_1)*\sum_{x,y}w(x,y)\begin{bmatrix}
    I_x(\sigma_D)^2&I_xI_y(\sigma_D)\\I_xI_y(\sigma_D)&I_y^2(\sigma_D)
    \end{bmatrix}\]
    \begin{itemize}
        \item $\sigma_D$: Gaussian in derivative calculation
        \item Gaussian in windowing function
    \end{itemize}
    \item Cornerness function/Corner response function, pull two strong eigenvalues
    \[\theta=det(M)-\alpha trace(M)^2=\lambda_1\lambda_2-\alpha(\lambda_1+\lambda_2)^2\]
    \begin{itemize}
        \item Take only the local maxima of $\theta$, where $\theta > $ threshold
    \end{itemize}
    \item Perform non-maximum suppression
    \begin{itemize}
        \item For each pixel that survived threshold, we only keep it if it's the largest in its neighborhood
    \end{itemize}
\end{itemize}
Harris Detector corner properties
\begin{itemize}
    \item Translation invariant
    \item Rotation invariant
    \begin{itemize}
        \item Corner response score is invariant to image rotation since it is decided by the eigenvalues, which are unaffected by rotation
    \end{itemize}
    \item NOT scale invariant
    \begin{itemize}
        \item SIFT detector (to be covered later) is scale invariant
    \end{itemize}
\end{itemize}
Scale invariant detection: How do we choose region sizes independently in each image?
\begin{itemize}
    \item Goal: design a function which is ``scale invariant"
    \begin{itemize}
        \item Ex: average intensity
    \end{itemize}
    \item Common approach to choose scale: take a local maximum of this function, dependent on IV region size
    \item Covariant with image scale
    \item What is a ``good" function for scale selection?
    \begin{itemize}
        \item One stable peak
    \end{itemize}
\end{itemize}
Kernel choices for scale invariant detection
\begin{itemize}
    \item Use function $f=$ kernel $ * $ image
    \item Choices
    \begin{itemize}
        \item Laplacian
        \[L=\sigma^2\left(G_{xx}(x,y,\sigma) + G_{yy}(x,y,\sigma)\right)\]
        \begin{itemize}
            \item Detects blobs (good features): a locally bright or dark spot
        \end{itemize}
        \item Difference of Gaussians (as in gaussian/normal distribution)
        \[DoG=G(x,y,k\sigma)-G(x,y,\sigma)\]
        \begin{itemize}
            \item $k$ is a parameter since higher variance means looking at a larger window (larger window size minus smaller window size)
            \item $k\in \mathbb R^+$
            \item Of note: computationally cheaper than Laplacian
        \end{itemize}
        where
        \[G(x,y,\sigma)=\frac{1}{2\pi\sigma}e^{-\frac{x^2+y^2}{2\sigma^2}}\]
    \end{itemize}
\end{itemize}
Scale Invariant Detectors
\begin{itemize}
    \item Finding keypoints using DoG
    \begin{itemize}
        \item Find local maximum of:
        \begin{itemize}
            \item Difference of Gaussians in space and scale
            \item Subtract differences between adjacent Gaussians, with consecutive Gaussians scaled by scalar multiplier $k$
        \end{itemize}
    \end{itemize}
    \item Summary: we want to find a keypoint that is scale and rotation-invariant
    \begin{itemize}
        \item Build a Gaussian pyramid
        \item Take DoG
        \item Keep 3D extrema in $(x,y,\sigma)\to (x,y)$ is keypoint location and $\sigma$ is the true scale 
    \end{itemize}
\end{itemize}
Local Features and Descriptors
\begin{itemize}
    \item How to describe points for matching?
    \item Invariant to transformations (rotation, translation, scale, etc.) and distinctive
\end{itemize}
